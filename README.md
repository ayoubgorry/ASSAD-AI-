# ARCHITECTURE TECHNIQUE - ASSAD AI (CAN 2025)

## Table des MatiÃ¨res
1. [Vue d'ensemble](#vue-densemble)
2. [Architecture gÃ©nÃ©rale](#architecture-gÃ©nÃ©rale)
3. [Flux de donnÃ©es](#flux-de-donnÃ©es)
4. [SystÃ¨me RAG expliquÃ©](#systÃ¨me-rag-expliquÃ©)
5. [Composants dÃ©taillÃ©s](#composants-dÃ©taillÃ©s)
6. [Logique IA cohÃ©rente](#logique-ia-cohÃ©rente)
7. [Configuration et dÃ©ploiement](#configuration-et-dÃ©ploiement)

---

## Vue d'ensemble

**ASSAD AI : CAN 2025 Assistant** est un systÃ¨me de question-rÃ©ponse basÃ© sur **RAG (Retrieval-Augmented Generation)** qui rÃ©pond aux questions sur le tournoi de la Coupe d'Afrique des Nations 2025 au Maroc.

### Stack technologique
- **Backend**: Python + FastAPI (API REST)
- **Frontend**: React.js (Interface Chat)
- **LLM**: Google Gemini 3 Pro Preview
- **Embeddings**: Sentence Transformers (all-MiniLM-L6-v2)
- **Base vectorielle**: FAISS (Facebook AI Similarity Search)
- **Framework IA**: LangChain (orchestration)

---

## Architecture gÃ©nÃ©rale

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                    INTERFACE UTILISATEUR (React)                 â”‚
â”‚  â€¢ Chat interface responsive avec Tailwind CSS                   â”‚
â”‚  â€¢ Gestion des messages (user/assistant)                         â”‚
â”‚  â€¢ Communication HTTP POST /chat endpoint                        â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                           â”‚
                    HTTP POST (Port 8000)
                    Content-Type: application/json
                           â”‚
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                 BACKEND - RAG CHAIN (FastAPI)                    â”‚
â”‚                   http://127.0.0.1:8000                          â”‚
â”‚                                                                   â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”‚
â”‚  â”‚ STEP 1: EMBEDDING & RETRIEVAL                           â”‚    â”‚
â”‚  â”‚    â€¢ Embedding question avec HuggingFace (384D)         â”‚    â”‚
â”‚  â”‚    â€¢ Recherche similarity dans FAISS (k=20)             â”‚    â”‚
â”‚  â”‚    â€¢ RÃ©cupÃ©ration des 20 documents les plus similaires  â”‚    â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â”‚
â”‚                           â”‚                                       â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”‚
â”‚  â”‚ STEP 2: CONTEXT FORMATTING                              â”‚    â”‚
â”‚  â”‚    â€¢ Formatage des documents rÃ©cupÃ©rÃ©s                  â”‚    â”‚
â”‚  â”‚    â€¢ Construction du contexte enrichi                   â”‚    â”‚
â”‚  â”‚    â€¢ Fusion avec le template de prompt                  â”‚    â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â”‚
â”‚                           â”‚                                       â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”‚
â”‚  â”‚ STEP 3: LLM GENERATION                                  â”‚    â”‚
â”‚  â”‚    â€¢ Appel Ã  Google Gemini 3 Pro Preview                â”‚    â”‚
â”‚  â”‚    â€¢ Temperature = 0 (rÃ©ponses dÃ©terministes)           â”‚    â”‚
â”‚  â”‚    â€¢ GÃ©nÃ©ration de rÃ©ponse en franÃ§ais                  â”‚    â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â”‚
â”‚                           â”‚                                       â”‚
â”‚              JSON Response retournÃ© au frontend                   â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                           â”‚
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚        BASE DE DONNÃ‰ES VECTORIELLE - FAISS INDEX                â”‚
â”‚         faiss_index_can2025/index.faiss                          â”‚
â”‚  â€¢ Embeddings crÃ©Ã©s avec HuggingFace Sentence Transformers      â”‚
â”‚  â€¢ ~1000+ documents issus de 7 fichiers JSON sources            â”‚
â”‚  â€¢ Recherche O(1) approximÃ© en espace vectoriel 384D            â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

---

## Flux de donnÃ©es

### Phase 1: Indexation (Une seule fois - offline)

```
JSON FILES (DATA SOURCES)
    â†“
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ config.py                               â”‚
â”‚ â€¢ Chemins fichiers JSON                â”‚
â”‚ â€¢ Aliases Ã©quipes (Maroc â†’ MAR)        â”‚
â”‚ â€¢ Config chunking (taillemax documents)â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
               â†“
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ load_docs.py                            â”‚
â”‚ â€¢ Charge 7 fichiers JSON                â”‚
â”‚ â€¢ Normalise noms d'Ã©quipes             â”‚
â”‚ â€¢ Formate documents (markdown)         â”‚
â”‚ â€¢ CrÃ©e mÃ©tadonnÃ©es riches:             â”‚
â”‚   - type (match, team, player, etc)    â”‚
â”‚   - Ã©quipes concernÃ©es                 â”‚
â”‚   - date, stade, phases                â”‚
â”‚   - source (fichier d'origine)         â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
               â†“
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ embeddings.py - create_vector_db()      â”‚
â”‚ â€¢ ModÃ¨le: sentence-transformers/       â”‚
â”‚          all-MiniLM-L6-v2              â”‚
â”‚ â€¢ CrÃ©e embeddings vectoriels (384D)    â”‚
â”‚ â€¢ CrÃ©e index FAISS local               â”‚
â”‚ â€¢ Sauvegarde: faiss_index_can2025/     â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
               â†“
        INDEX FAISS (READY)
        ~960 documents indexÃ©s
```

### Phase 2: RequÃªte utilisateur (Runtime)

```
USER INPUT (React Frontend)
â”‚
â”œâ”€ Question: "Quel est le calendrier des demi-finales ?"
â”‚
â†“
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ rag_chain.py - /chat endpoint (FastAPI)  â”‚
â”‚                                           â”‚
â”‚ STEP 1: Embedding                        â”‚
â”‚  question â†’ embedding vector (384 dims)  â”‚
â”‚                                           â”‚
â”‚ STEP 2: Retrieval (FAISS)                â”‚
â”‚  similarity_search(query, k=20)          â”‚
â”‚  â†“ Returns top 20 similar documents      â”‚
â”‚                                           â”‚
â”‚ STEP 3: Context Building                 â”‚
â”‚  Format: "--- SOURCE: matches.json ---   â”‚
â”‚           Match CAN 2025 - Match #87:    â”‚
â”‚           Maroc 2 Cameroun 1             â”‚
â”‚            Date: 2025-02-04            â”‚
â”‚            Stade: Stade Casablanca"    â”‚
â”‚                                           â”‚
â”‚ STEP 4: Prompt Template                  â”‚
â”‚  "Tu es expert CAN 2025...               â”‚
â”‚   CONTEXTE: {context}                   â”‚
â”‚   QUESTION: {question}                  â”‚
â”‚   RÃ‰PONSE:"                              â”‚
â”‚                                           â”‚
â”‚ STEP 5: LLM Call (Google Gemini)         â”‚
â”‚  temperature=0 (dÃ©terministe)           â”‚
â”‚  response = llm(prompt)                  â”‚
â”‚                                           â”‚
â”‚ STEP 6: Parse & Return                   â”‚
â”‚  {"response": "Les demi-finales..."}    â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
               â†“
        RESPONSE TO FRONTEND
        
User sees: "Le Maroc joue en demi-finale 
le 4 fÃ©vrier 2025 contre le Cameroun..."
```

---

## SystÃ¨me RAG expliquÃ©

### Qu'est-ce que RAG ?

**RAG = Retrieval-Augmented Generation**

C'est une approche qui combine trois Ã©tapes:

1. **Retrieval (RÃ©cupÃ©ration)** : Trouver les documents pertinents dans la base vectorielle
2. **Augmented** : Augmenter le contexte du LLM avec ces documents spÃ©cifiques
3. **Generation** : GÃ©nÃ©rer une rÃ©ponse basÃ©e sur ce contexte enrichi

### Avantages du RAG pour ce projet

| Avantage | BÃ©nÃ©fice |
|----------|----------|
|  **FactualitÃ©** | RÃ©ponses basÃ©es sur donnÃ©es rÃ©elles du CAN 2025 |
|  **Pas d'hallucinations** | LLM ne peut pas inventer de faits du tournoi |
|  **Contexte actuel** | IntÃ¨gre CAN 2025 sans rÃ©entraÃ®nement du modÃ¨le |
|  **TraÃ§abilitÃ©** | MÃ©tadonnÃ©es source des rÃ©ponses |
|  **EfficacitÃ©** | k=20 documents plutÃ´t que lire tous les ~960 |

### Processus step-by-step

```
1ï¸ ENCODING QUESTION
   "Qui a marquÃ© contre le Maroc ?"
   â†“
   Sentence Transformers encode:
   [0.124, -0.089, 0.456, ..., 0.234]  (384 dimensions)
   
   Capture sÃ©mantique:
   â€¢ "marquÃ©" â†’ sÃ©mantique = action (but/goal)
   â€¢ "Maroc" â†’ sÃ©mantique = Ã©quipe
   â€¢ "contre" â†’ sÃ©mantique = adversaire

2ï¸ SIMILARITY SEARCH in FAISS
   Calcul cosine similarity avec tous les embeddings
   â†“ Retourne top-k matches
   
   RÃ©sultats (similarity score):
   0.95 â† "Match Maroc 1 Gabon 0 - Buteur: Ziyech"
   0.94 â† "Maroc 2 Angola 1 - Ziyech 23', Boufal 67'"
   0.92 â† "Match Nigeria vs Cameroun 1-0"
   ...
   â†“ Top 20 documents

3ï¸ CONTEXT ASSEMBLY
   Fusion des 20 documents dans prompt:
   
   "--- SOURCE: matches.json ---
     Match CAN 2025 - Match #1
     Maroc 1 Gabon 0
    Buteur: Sofyan Amrabat 45'
    Stade: Stade Fes
    
    --- SOURCE: matches.json ---
    Match #2: Maroc 2 Angola 1
    ..."

4ï¸ PROMPT TEMPLATE INJECTION
   Template = "Tu es expert CAN 2025.
              RÃ©ponds factuellement.
              
              CONTEXTE:
              [20 docs ici]
              
              QUESTION:
              Qui a marquÃ© contre le Maroc ?
              
              RÃ‰PONSE:"

5ï¸ LLM PROCESSING
   Gemini 3 Pro lit:
   â€¢ Le contexte (20 documents spÃ©cifiques)
   â€¢ La question utilisateur
   â†“ GÃ©nÃ¨re rÃ©ponse factuelle en franÃ§ais
   
   Output: "Sofyan Amrabat a marquÃ© contre 
            le Maroc Ã  la 45e minute du 
            match nÂ°1, et Hakim Ziyech..."

6ï¸ RESPONSE PARSING
   StrOutputParser extrait texte brut
   â†“
   {"response": "Sofyan Amrabat a marquÃ©..."}
```

### ModÃ¨le d'Embedding: all-MiniLM-L6-v2

```
HuggingFace Sentence Transformers
â”‚
â”œâ”€ CaractÃ©ristiques:
â”‚  â€¢ LÃ©ger (22M paramÃ¨tres)
â”‚  â€¢ Rapide (~50ms par texte)
â”‚  â€¢ Dimension: 384
â”‚  â€¢ PrÃ©-entraÃ®nÃ© sur corpus multilingual
â”‚  â€¢ OptimisÃ© pour semantic similarity
â”‚
â”œâ”€ Processus:
â”‚  1. Tokenisation du texte
â”‚  2. Passage dans BERT encoder
â”‚  3. Mean pooling des token embeddings
â”‚  4. Normalisation L2
â”‚  â†“
â”‚  Vecteur 384D reprÃ©sentant la sÃ©mantique
â”‚
â””â”€ RÃ©sultat:
   Peut comparer similarity entre:
   â€¢ "Maroc vs Gabon" â†” "Match Maroc Gabon"
   â€¢ "Qui joue demi-finale ?" â†” "Demi-finale 2025"
   â€¢ "SÃ©nÃ©gal" â†” "Ã‰quipe SÃ©nÃ©gal" (mÃªme Ã©quipe)
```

### Pourquoi k=20 ?

Le systÃ¨me rÃ©cupÃ¨re `k=20` plus proches voisins car:

- **ComplÃ©tude**: Assure assez de contexte pour rÃ©pondre complÃ¨tement
- **Couverture**: GÃ¨re donnÃ©es fragmentÃ©es (matchs rÃ©partis sur plusieurs documents)
- **Performance**: 20 docs = bon Ã©quilibre entre tokens consommÃ©s et contexte utile
- **DiversitÃ©**: RÃ©cupÃ¨re diffÃ©rentes perspectives sur un mÃªme sujet

### Temperature = 0 (DÃ©terministe)

```python
llm = ChatGoogleGenerativeAI(
    model="gemini-3-pro-preview",
    temperature=0  # â† DÃ©terministe
)
```

**Pourquoi temperature=0?**
- **DÃ©terminisme**: MÃªme question â†’ MÃªme rÃ©ponse toujours
- **FactualitÃ©**: Pas de variabilitÃ© crÃ©ative nuisant Ã  l'exactitude
- **Sports**: Important pour donnÃ©es factuelles (scores, dates, noms)

---

## Composants dÃ©taillÃ©s

### 1ï¸âƒ£ config.py - Configuration centralisÃ©e

**ResponsabilitÃ©**: Centraliser toutes les constantes du projet

```python
DATA_FOLDER = "../data/json"  # Chemin donnÃ©es

FILES = {
    "matches": "matches.json",           # ~100 matchs
    "teams": "equipes_qualifiees.json",  # 24 Ã©quipes
    "coaches": "coach.json",             # SÃ©lectionneurs
    "squads": "joueurs_equipe.json",     # Effectifs (~600 joueurs)
    "stadiums": "stades.json",           # Stades marocains
    "standings": "classement_phase_groupe.json",
    "best_thirds": "classement_meilleurs_trois.json"
}

TEAM_ALIASES = {
    "Maroc": ["Maroc", "Morocco", "MAR", "Lions de l'Atlas"],
    "Gabon": ["Gabon", "GAB", "PanthÃ¨res"],
    "SÃ©nÃ©gal": ["SÃ©nÃ©gal", "Senegal", "SEN", "Lions"],
    # ... 21 autres Ã©quipes
}

CHUNKING_CONFIG = {
    "matches": {"max_tokens": 2000, "overlap": 200},
    "teams": {"max_tokens": 1500, "overlap": 100},
    "players": {"max_tokens": 500, "overlap": 50}
}
```

**Avantage**: Ã‰vite hardcodes, permet normalisation (MAR â†’ Maroc)

---

### 2ï¸ load_docs.py - ETL & Document Creation

**ResponsabilitÃ©**: Charger, formater et transformer donnÃ©es JSON en Documents LangChain

```
load_all_can2025_data()
â”œâ”€ Charge 7 fichiers JSON
â”œâ”€ Normalise tous noms d'Ã©quipes (aliases)
â”œâ”€ Process par type:
â”‚
â”œâ”€ process_matches(data)
â”‚  â€¢ Document match dÃ©taillÃ© (rÃ©sultat + buteurs + cartons)
â”‚  â€¢ Document match rÃ©sumÃ© (1 ligne)
â”‚  â€¢ Document Ã©vÃ©nement (finales/demis)
â”‚  â†“ ~300 documents
â”‚
â”œâ”€ process_teams(data_sources)
â”‚  â€¢ Profil complet (palmarÃ¨s + sÃ©lectionneur + effectif)
â”‚  â€¢ Profil rÃ©sumÃ©
â”‚  â†“ ~48 documents
â”‚
â”œâ”€ process_players(data)
â”‚  â€¢ Fiche joueur individuelle (nom, club, poste)
â”‚  â†“ ~600 documents
â”‚
â”œâ”€ process_standings(data)
â”‚  â€¢ Tableau classement par groupe
â”‚  â†“ ~4 documents
â”‚
â””â”€ process_stadiums(data)
   â€¢ Info stade (capacitÃ©, ville, localisation)
   â†“ ~8 documents

TOTAL: ~960 documents avec mÃ©tadonnÃ©es riches
```

**MÃ©tadonnÃ©es ajoutÃ©es** (critiques pour FAISS):

```python
Document(
    page_content=" DEMI-FINALE - CAN 2025\nMaroc 2 Cameroun 1...",
    metadata={
        "type": "match_detailed",
        "match_number": "87",
        "phase": "Finales",
        "team_home": "Maroc",  # NORMALISÃ‰
        "team_away": "Cameroun",  # NORMALISÃ‰
        "teams": ["Maroc", "Cameroun"],  # Pour recherches
        "date": "2025-02-04",
        "stadium": "Stade Casablanca",
        "score": "2-1",
        "source": "matches.json"
    }
)
```

---

### 3ï¸ embeddings.py - Vector DB Creation

**ResponsabilitÃ©**: CrÃ©er et sauvegarder l'index FAISS

```python
def create_vector_db():
    # 1. Charge documents (~960 docs)
    chunks = load_all_can2025_data()
    
    # 2. Initialise embedding model
    embedding_model = HuggingFaceEmbeddings(
        model_name="sentence-transformers/all-MiniLM-L6-v2"
    )
    
    # 3. CrÃ©e FAISS index
    vector_db = FAISS.from_documents(chunks, embedding_model)
    # Pour chaque document:
    #   text â†’ embedding (384D) â†’ index dans FAISS
    
    # 4. Sauvegarde locale
    vector_db.save_local("faiss_index_can2025")
    # Fichiers crÃ©Ã©s:
    # - index.faiss (vecteurs)
    # - docstore.pkl (mÃ©tadonnÃ©es)
    # - index.pkl (mapping)
```

**RÃ©sultat**: Fichier binaire `index.faiss` permettant recherches O(1) approximÃ©

---

### 4ï¸âƒ£ rag_chain.py (alias interface.py) - Backend API & ChaÃ®ne RAG

**Architecture globale:**

```python
# 1. CHARGEMENT PERSISTENT (au dÃ©marrage du serveur)
embedding_model = HuggingFaceEmbeddings(...)  # ~150MB RAM
vector_db = FAISS.load_local("faiss_index_can2025", ...)
retriever = vector_db.as_retriever(
    search_type="similarity",
    search_kwargs={"k": 20}  # TOP 20 documents
)

# 2. LLM CONFIG
llm = ChatGoogleGenerativeAI(
    model="gemini-3-pro-preview",
    temperature=0,  # DÃ©terministe
    google_api_key=os.getenv("GOOGLE_API_KEY")
)

# 3. PROMPT TEMPLATE
template = """Tu es un expert de la CAN 2025. RÃ©ponds prÃ©cisÃ©ment Ã  la question 
en utilisant le contexte fourni. Si tu ne sais pas, dis que tu n'as pas l'information.

CONTEXTE :
{context}

QUESTION :
{question}

RÃ‰PONSE :"""

# 4. CHAÃNE RAG (LangChain)
rag_chain = (
    {"context": retriever | format_docs, "question": RunnablePassthrough()}
    | prompt
    | llm
    | StrOutputParser()
)

# 5. ENDPOINT FASTAPI
@app.post("/chat")
async def chat(question: Question):
    response = rag_chain.invoke(question.query)
    return {"response": response}

# 6. CORS (Development)
app.add_middleware(
    CORSMiddleware,
    allow_origins=["*"],  # Ã€ restreindre en production
    allow_methods=["*"],
    allow_headers=["*"]
)
```

**Flux d'exÃ©cution:**

```
Input: {"query": "Qui a marquÃ© pour le Maroc ?"}
  â†“
Retriever: rÃ©cupÃ¨re top 20 docs contenant "Maroc" + "buteur"
  â†“
format_docs(): transforme en texte lisible:
  "--- SOURCE: matches.json ---
    Match CAN 2025 - Match #1
   Maroc 1 Gabon 0
   Buteur: Sofyan Amrabat 45'"
  â†“
Prompt Template: injection du contexte
  â†“
ChatGoogleGenerativeAI: gÃ©nÃ¨re rÃ©ponse via Gemini
  â†“
StrOutputParser: extrait le texte brut
  â†“
Output: {"response": "Sofyan Amrabat a marquÃ©..."}
```

**CORS Configuration:**

```python
CORSMiddleware(
    allow_origins=["*"],           
    allow_credentials=False,       
    allow_methods=["*"],
    allow_headers=["*"]
)
```

Production: Restreindre Ã  origin frontend uniquement

---

### 5ï¸âƒ£ Frontend (App.js) - Interface utilisateur React

**ResponsabilitÃ©**: Chat interface moderne et responsive

**Flux utilisateur:**

```
INTERFACE REACT
â”‚
â”œâ”€ Ã‰tat initial
â”‚  Message welcome: "Bienvenue sur ASSAD AI"
â”‚
â”œâ”€ Suggestions rapides (3 boutons, visible 1Ã¨re fois)
â”‚  â€¢ "Stades & Villes"
â”‚  â€¢ "Calendrier demi-finale"
â”‚  â€¢ "Informations sur le Gabon"
â”‚
â”œâ”€ User input textarea
â”‚  â€¢ Shift+Enter = nouvelle ligne
â”‚  â€¢ Enter seul = envoi du message
â”‚
â”œâ”€ On handleSend():
â”‚  â”œâ”€ Valide input (non vide, pas loading)
â”‚  â”œâ”€ Ajoute message user au state
â”‚  â”œâ”€ Clear input field
â”‚  â”œâ”€ POST http://127.0.0.1:8000/chat
â”‚  â”‚  headers: {"Content-Type": "application/json"}
â”‚  â”‚  body: {"query": "user input"}
â”‚  â”œâ”€ Affiche loading indicator
â”‚  â”œâ”€ Attend rÃ©ponse JSON
â”‚  â”œâ”€ Ajoute rÃ©ponse assistant au state
â”‚  â””â”€ GÃ¨re erreurs (CORS, timeout, API down)
â”‚
â”œâ”€ Rendu des messages
â”‚  â”œâ”€ User message:
â”‚  â”‚  â€¢ Fond rouge (#c1272d)
â”‚  â”‚  â€¢ AlignÃ© Ã  droite
â”‚  â”‚  â€¢ Badge "Expert CAF"
â”‚  â”‚
â”‚  â”œâ”€ Assistant message:
â”‚  â”‚  â€¢ Fond blanc
â”‚  â”‚  â€¢ AlignÃ© Ã  gauche
â”‚  â”‚  â€¢ Border gauche vert (#004d3d)
â”‚  â”‚  â€¢ ReactMarkdown pour formatage
â”‚  â”‚    - Listes avec puces
â”‚  â”‚    - Texte en gras (couleur rouge)
â”‚  â”‚
â”‚  â””â”€ Loading state:
â”‚     â€¢ Spinner animÃ©
â”‚     â€¢ "ASSAD prÃ©pare sa rÃ©ponse..."
â”‚
â””â”€ Design & Styling
   â€¢ Couleurs CAN 2025:
     - Vert dominant (#004d3d)
     - Rouge accent (#c1272d)
     - Or dÃ©coration (#c19d56)
   â€¢ Responsive Tailwind CSS
   â€¢ Logo CAN 2025 dans header
   â€¢ Status "En ligne" (green pulsing dot)
   â€¢ Footer: "TotalEnergies CAF"
```

**Technologies utilisÃ©es:**

```javascript
import React, { useState, useRef, useEffect } from 'react';
import ReactMarkdown from 'react-markdown';
import { Loader2, Send, Sparkles, Trophy, MapPin, Calendar } from 'lucide-react';
```

**Gestion d'Ã©tat:**

```javascript
const [messages, setMessages] = useState([...])     // Historique chat
const [input, setInput] = useState('')              // Texte input
const [isLoading, setIsLoading] = useState(false)   // Ã‰tat requÃªte API
const messagesEndRef = useRef(null)                 // Auto-scroll bottom
```

---

## Logique IA cohÃ©rente

### Principes de design IA

| Principe | Implementation | Avantage |
|----------|-----------------|----------|
| **FactualitÃ©** | RAG avec donnÃ©es rÃ©elles JSON | Pas d'hallucinations |
| **DÃ©terminisme** | temperature=0 | RÃ©ponses reproductibles |
| **Contexte enrichi** | k=20 documents pertinents | ComprÃ©hension complÃ¨te |
| **FranÃ§ais natif** | Prompt + LLM multilingue | RÃ©ponses naturelles |
| **Normalisation** | Aliases d'Ã©quipes (Maroc/MAR) | Reconnaissance flexible |
| **Typage document** | metadata (type, team, date) | Recherche prÃ©cise par phase |
| **Grounding** | Documents source dans metadata | TraÃ§abilitÃ© rÃ©ponses |

### Exemple d'exÃ©cution dÃ©taillÃ©

**Question utilisateur:** "Quand joue le Maroc en phase finale ?"

```
Ã‰TAPE 1: Embedding question
â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
"Quand joue le Maroc en phase finale ?"
  â†“ Sentence Transformers
[0.123, -0.456, 0.789, ..., 0.234]  (384 dimensions)

Capture sÃ©mantique:
â€¢ "Maroc" â†’ Ã©quipe
â€¢ "joue" â†’ action (match)
â€¢ "phase finale" â†’ tournoi advanced stages
â€¢ "quand" â†’ date/timing


Ã‰TAPE 2: Retrieval FAISS
â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
Compare embedding avec tous les 960 docs
  â†“ Cosine similarity
RÃ©sultats (similarity score):
  0.95 â† " DEMI-FINALE - CAN 2025
           Date : 2025-02-04
           Match : Maroc vs Cameroun"
  
  0.94 â† "Match CAN 2025 - Match #87
          Maroc [team_home]
          Phase: Finales
          Date: 2025-02-04"
  
  0.92 â† "Maroc - CAN 2025 Team Profile
          Participation: 6
          Best Result: Champion"
  
  0.88 â† "Player: Hakim Ziyech (Maroc)"
  
  ...18 autres docs pertinents...


Ã‰TAPE 3: Context Assembly
â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
format_docs(top_20_documents):

--- SOURCE: matches.json ---
ğŸ† DEMI-FINALE - CAN 2025

 Date : 2025-02-04
 Stade : Stade Casablanca
 Match : Maroc vs Cameroun
 Match : 87
 Score: 2-1

--- SOURCE: matches.json ---
Match CAN 2025 - Match #87: Maroc 2 Cameroun 1
(2025-02-04, Stade Casablanca)

[...18 autres docs pertinents...]


Ã‰TAPE 4: Prompt Template
â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
Tu es un expert de la CAN 2025. RÃ©ponds prÃ©cisÃ©ment Ã  la question 
en utilisant le contexte fourni. Si tu ne sais pas, dis que tu n'as pas l'information.

CONTEXTE :
--- SOURCE: matches.json ---
 DEMI-FINALE - CAN 2025
 Date : 2025-02-04
 Stade : Stade Casablanca
 Match : Maroc vs Cameroun

QUESTION :
Quand joue le Maroc en phase finale ?

RÃ‰PONSE :


Ã‰TAPE 5: LLM Generation (Gemini 3 Pro)
â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
[Gemini reads contexte]
  â†“ Voit "Maroc" dans document
  â†“ Voit "DEMI-FINALE" et date "2025-02-04"
  â†“ Voit "Match #87" et "Stade Casablanca"
  â†“ GÃ©nÃ¨re rÃ©ponse factuelle basÃ©e sur contexte

Output Gemini:
"Le Maroc joue en demi-finale le 4 fÃ©vrier 2025 contre 
le Cameroun au Stade Casablanca. Cette demi-finale 
est le match numÃ©ro 87 du tournoi."


Ã‰TAPE 6: Response Parsing
â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
StrOutputParser extrait le texte brut
  â†“
{"response": "Le Maroc joue en demi-finale le 4 fÃ©vrier 2025..."}


Ã‰TAPE 7: Frontend Display
â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
React affiche dans message assistant:
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  EXPERT CAF                           â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Le Maroc joue en demi-finale le 4       â”‚
â”‚ fÃ©vrier 2025 contre le Cameroun au      â”‚
â”‚ Stade Casablanca. Cette demi-finale     â”‚
â”‚ est le match numÃ©ro 87 du tournoi.      â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

### Cas d'usage maÃ®trisÃ©s

 **Questions factuelles sur les matchs**
```
Q: "Qui a marquÃ© 2 buts en groupe contre l'Ã‰gypte ?"
A: Recherche docs (type:match, team:Ã‰gypte) â†’ buteurs â†’ rÃ©ponse
```

 **RequÃªtes sur les Ã©quipes**
```
Q: "Quel est l'effectif du SÃ©nÃ©gal ?"
A: RÃ©cupÃ¨re document team_complete â†’ squad â†’ affiche 23 joueurs
```

 **Calendrier et phases**
```
Q: "Quand sont les quarts de finale ?"
A: RÃ©cupÃ¨re documents (type:event, etape:quart) â†’ dates
```

 **Informations stades**
```
Q: "Quel stade pour la finale ?"
A: RÃ©cupÃ¨re document stadium + metadata â†’ rÃ©ponse
```

 **Comparaisons Ã©quipes**
```
Q: "Maroc vs SÃ©nÃ©gal, qui a le meilleur historique ?"
A: RÃ©cupÃ¨re team_complete pour 2 Ã©quipes â†’ compare palmarÃ¨s
```

### Limitations intentionnelles

 **Pas de prÃ©dictions**
```
Q: "Qui va gagner la finale ?"
A: "Je n'ai pas l'information sur les rÃ©sultats futurs"
```

 **Pas de donnÃ©es hors CAN 2025**
```
Q: "Comment va le Maroc Ã©conomiquement ?"
A: "Je suis expert en CAN 2025, pas en Ã©conomie"
```

 **Pas de spÃ©culations**
```
Q: "Pourquoi Ziyech n'a pas jouÃ© ?"
A: "Cette information n'est pas disponible dans mes donnÃ©es"
```

---

## Configuration et dÃ©ploiement

### PrÃ©requis

```bash
# Python 3.10+
python --version  # â‰¥ 3.10

# Node.js 16+
node --version  # â‰¥ 16

# Google Gemini API Key
# https://console.cloud.google.com/
```

### Installation des dÃ©pendances

**Backend:**
```bash
cd app2
pip install fastapi uvicorn python-dotenv
pip install langchain langchain-core langchain-google-genai
pip install langchain-huggingface sentence-transformers
pip install langchain-community faiss-cpu
```

**Frontend:**
```bash
cd can2025-chat
npm install react-markdown
```

### Variables d'environnement

**CrÃ©er fichier `.env` dans `app2/`:**

```env
GOOGLE_API_KEY=AIzaSy...  # ClÃ© Google Gemini API
```

Obtenir la clÃ©:
1. Google Cloud Console: https://console.cloud.google.com/
2. CrÃ©er projet
3. Activer "Generative Language API"
4. CrÃ©er clÃ© API

### Ã‰tapes de dÃ©marrage

**1. CrÃ©er l'index FAISS** (une seule fois):
```bash
cd app2
python embeddings.py
# Output: " Indexation terminÃ©e avec succÃ¨s !"
# Fichiers crÃ©Ã©s: faiss_index_can2025/
```

**2. Lancer le backend FastAPI** (terminal 1):
```bash
cd app2
python rag_chain.py
# Output: "Uvicorn running on http://127.0.0.1:8000"
```

**3. Lancer le frontend React** (terminal 2):
```bash
cd can2025-chat
npm start
# Output: "Compiled successfully!
#         Frontend running on http://localhost:3000"
```

**4. AccÃ©der Ã  l'application:**
```
http://localhost:3000
```

### Diagramme de dÃ©ploiement

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚   DÃ‰VELOPPEMENT (localhost)         â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚                                      â”‚
â”‚  Frontend React          Backend API â”‚
â”‚  http://localhost:3000   :8000       â”‚
â”‚  (npm start)             (uvicorn)   â”‚
â”‚       â”‚                      â”‚       â”‚
â”‚       â””â”€â”€â”€â”€â”€â”€POST /chatâ”€â”€â”€â”€â”€â”€â”˜       â”‚
â”‚                                      â”‚
â”‚  DonnÃ©es: ../data/json/             â”‚
â”‚  Index: ./faiss_index_can2025/      â”‚
â”‚  Models cache: ~/.cache/huggingface  â”‚
â”‚                                      â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜

â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚   PRODUCTION (Optionnel)            â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚                                      â”‚
â”‚  Frontend:  Vercel / Netlify        â”‚
â”‚  Backend:   Railway / Render        â”‚
â”‚  Index:     AWS S3 / Google Storage â”‚
â”‚                                      â”‚
â”‚   CORS: Restreindre Ã  origin      â”‚
â”‚   API Key: Variable d'env secrets â”‚
â”‚                                      â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

### Performance et ressources

| MÃ©trique | Valeur | Notes |
|----------|--------|-------|
| **Temps indexation** | ~30 sec | Une seule fois |
| **Temps embedding question** | ~50ms | Sentence Transformers |
| **Temps FAISS retrieval** | ~5ms | Nearest neighbor search |
| **Temps gÃ©nÃ©ration LLM** | ~1-2 sec | Appel Gemini API |
| **Temps total requÃªte** | ~2-3 sec | De question Ã  rÃ©ponse |
| **MÃ©moire (runtime)** | ~500MB | Embeddings + index |
| **Espace disque** | ~50MB | index.faiss |

---

## RÃ©sumÃ© architecture

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚         DONNÃ‰ES SOURCE (7 fichiers JSON)                â”‚
â”‚  matches | teams | coaches | squads | stadiums |       â”‚
â”‚  standings | best_thirds                                â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                     â”‚
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚   TRANSFORMATION (load_docs.py)                         â”‚
â”‚   â€¢ Normalise noms Ã©quipes (Aliases)                    â”‚
â”‚   â€¢ Formate documents en markdown                       â”‚
â”‚   â€¢ Ajoute mÃ©tadonnÃ©es (type, teams, date, source)      â”‚
â”‚   â†“ ~960 LangChain Documents                            â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                     â”‚
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚   VECTORISATION (embeddings.py)                         â”‚
â”‚   â€¢ Sentence Transformers (384D)                        â”‚
â”‚   â€¢ FAISS Index (similarity search)                     â”‚
â”‚   â†“ index.faiss (optimisÃ© pour recherche rapide)        â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                     â”‚
        â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
        â”‚                         â”‚
â”Œâ”€â”€â”€â”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”€â”         â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ BACKEND      â”‚         â”‚ FRONTEND (React)  â”‚
â”‚ (FastAPI)    â”‚         â”‚ (Chat Interface)  â”‚
â”‚ :8000        â”‚         â”‚ localhost:3000    â”‚
â”‚              â”‚         â”‚                   â”‚
â”‚ RAG Chain:   â”‚â—„â”€â”€â”€â”€â”€â”€â”€â”€â”¤ POST /chat        â”‚
â”‚ â€¢ Retriever  â”‚         â”‚ {"query": "..."}  â”‚
â”‚ â€¢ Prompt     â”‚         â”‚                   â”‚
â”‚ â€¢ LLM        â”‚         â”‚ JSON response     â”‚
â”‚ â€¢ Parser     â”‚         â”‚ {"response": "..."}
â”‚              â”‚         â”‚                   â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜         â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
       â”‚
       â””â”€â†’ Google Gemini 3 Pro API
           (gÃ©nÃ©ration rÃ©ponses)
```

---

## RÃ©sumÃ© des points clÃ©s

- **Architecture client-serveur** (React â†” FastAPI)
- **Pipeline RAG complet** (Retrieval â†’ Context â†’ Generation)
- **Embeddings sÃ©mantiques** (all-MiniLM-L6-v2 - 384D)
- **Index vectoriel FAISS** pour recherche O(1) approximÃ©
- **Normalisation Ã©quipes** via systÃ¨me d'aliases
- **MÃ©tadonnÃ©es riches** pour filtrage intelligent
- **LLM dÃ©terministe** (temperature=0)
- **Contexte enrichi** (k=20 documents par requÃªte)
- **Gestion erreurs** client-server robuste
- **Interface responsive** avec Tailwind CSS

---

**Cette architecture garantit une logique IA cohÃ©rente, factuelle et performante adaptÃ©e Ã  la CAN 2025.**

*Document gÃ©nÃ©rÃ© le 4 janvier 2026 | ASSAD AI Architecture v1.0*
